{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape is (44, 20) and Test labels shape is (44,)\n",
      "Validation data shape is (44, 20) and Validation labels shape is (44,)\n",
      "Train data shape is (209, 20) and Train labels shape is (209,)\n"
     ]
    }
   ],
   "source": [
    "#Load preprocessed dataset\n",
    "savedPath = \"../data/splittedData.pickle\"\n",
    "\n",
    "with open(savedPath, \"rb\") as input_file:\n",
    "    dataDict = pickle.load(input_file)\n",
    "\n",
    "testData = dataDict[\"testData\"]\n",
    "testLabels = dataDict[\"testLabels\"]\n",
    "validationData = dataDict[\"validationData\"]\n",
    "validationLabels = dataDict[\"validationLabels\"]\n",
    "trainData = dataDict[\"trainData\"]\n",
    "trainLabels = dataDict[\"trainLabels\"]\n",
    "\n",
    "testLabels = testLabels.astype(np.float32)\n",
    "validationLabels = validationLabels.astype(np.float32)\n",
    "trainLabels = trainLabels.astype(np.float32)\n",
    "\n",
    "print(\"Test data shape is {} and Test labels shape is {}\".format(testData.shape, testLabels.shape))\n",
    "print(\"Validation data shape is {} and Validation labels shape is {}\"\n",
    "      .format(validationData.shape, validationLabels.shape))\n",
    "print(\"Train data shape is {} and Train labels shape is {}\".format(trainData.shape, trainLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL PARAMS\n",
    "NUMBER_OF_FEATURES = 20\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCH = 200\n",
    "CHECK_GAP = 100\n",
    "ALPHA = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "xVals = tf.placeholder(shape=[None, NUMBER_OF_FEATURES], dtype=np.float32)\n",
    "yVals = tf.placeholder(shape=[None, 1], dtype=np.float32)\n",
    "\n",
    "weight = tf.Variable(tf.random_normal(shape=[NUMBER_OF_FEATURES, 1], mean=0.0, stddev=1))\n",
    "biais = tf.Variable(tf.random_normal(shape=[1, 1], mean=0.0, stddev=1))\n",
    "\n",
    "modelOutput = tf.add(tf.matmul(xVals, weight), biais)\n",
    "\n",
    "#Compute the loss\n",
    "weightAbs = tf.reduce_mean(tf.multiply(ALPHA, tf.abs(weight)))\n",
    "origLoss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=modelOutput, labels=yVals))\n",
    "loss = tf.add(weightAbs, origLoss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "trainStep = optimizer.minimize(loss)\n",
    "\n",
    "#Compute Accuracy\n",
    "prediction = tf.round(tf.nn.sigmoid(modelOutput))\n",
    "correctPrediction = tf.cast(tf.equal(prediction, yVals), dtype=np.float32)\n",
    "accuracy = tf.reduce_mean(correctPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 100 VALIDATION: loss = 2.156432628631592 and accuracy = 0.6363636255264282\n",
      "\n",
      "\n",
      "Step 200 VALIDATION: loss = 1.8107726573944092 and accuracy = 0.6590909361839294\n",
      "\n",
      "\n",
      "Step 300 VALIDATION: loss = 1.5660474300384521 and accuracy = 0.6590909361839294\n",
      "\n",
      "\n",
      "Step 400 VALIDATION: loss = 1.4005026817321777 and accuracy = 0.6818181872367859\n",
      "\n",
      "\n",
      "Step 500 VALIDATION: loss = 1.2582061290740967 and accuracy = 0.7272727489471436\n",
      "\n",
      "\n",
      "Step 600 VALIDATION: loss = 1.1559395790100098 and accuracy = 0.7272727489471436\n",
      "\n",
      "\n",
      "Step 700 VALIDATION: loss = 1.0749175548553467 and accuracy = 0.75\n",
      "\n",
      "\n",
      "Step 800 VALIDATION: loss = 1.0048878192901611 and accuracy = 0.7272727489471436\n",
      "\n",
      "\n",
      "Step 900 VALIDATION: loss = 0.9478007555007935 and accuracy = 0.7272727489471436\n",
      "\n",
      "\n",
      "Step 1000 VALIDATION: loss = 0.8986818790435791 and accuracy = 0.7272727489471436\n",
      "\n",
      "\n",
      "Step 1100 VALIDATION: loss = 0.8592897057533264 and accuracy = 0.75\n",
      "\n",
      "\n",
      "Step 1200 VALIDATION: loss = 0.8277779221534729 and accuracy = 0.7727272510528564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "steps = []\n",
    "lossVals = []\n",
    "accVals = []\n",
    "\n",
    "currentStep = 0\n",
    "trainDataSize = trainData.shape[0]\n",
    "np.random.seed(seed=18)\n",
    "\n",
    "for index in range(NUM_EPOCH) :\n",
    "    indexes = np.arange(trainDataSize)\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    highIndex = 0\n",
    "    while highIndex + BATCH_SIZE < trainDataSize :\n",
    "        batchIndexes = indexes[highIndex:highIndex + BATCH_SIZE]\n",
    "        highIndex = highIndex + BATCH_SIZE\n",
    "        \n",
    "        lss, _, acc = sess.run([loss, trainStep, accuracy], feed_dict={xVals: trainData[batchIndexes], \n",
    "                                                               yVals: trainLabels[batchIndexes].reshape((-1, 1))})    \n",
    "        currentStep = currentStep + 1\n",
    "#         print(\"Step {} Training: loss = {} and accuracy = {}\".format(currentStep, lss, acc))\n",
    "        \n",
    "        if currentStep % CHECK_GAP == 0 :\n",
    "            validationIndexes = np.arange(validationData.shape[0])\n",
    "            np.random.shuffle(validationIndexes)\n",
    "            lossVall, accVall = sess.run([loss, accuracy], feed_dict={xVals: validationData[validationIndexes], \n",
    "                                                               yVals: validationLabels[validationIndexes].reshape((-1, 1))})\n",
    "            steps.append(currentStep)\n",
    "            lossVals.append(lossVall)\n",
    "            accVals.append(accVall)\n",
    "            \n",
    "            print()\n",
    "            print(\"Step {} VALIDATION: loss = {} and accuracy = {}\".format(currentStep, lossVall, accVall))\n",
    "            print()\n",
    "\n",
    "#Accuracy on test set\n",
    "accTest = sess.run(accuracy, feed_dict={xVals: testData, yVals: testLabels.reshape((-1, 1))})\n",
    "print(\"ACCURACY ON TEST SET: {}\".format(accTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMetricDic = {\"steps\": steps, \n",
    "                  \"lossVals\": lossVals, \n",
    "                  \"accVals\": accVals, \n",
    "                  \"accTest\": accTest}\n",
    "savedPath = \"../data/lassoRegressionModelMetrics.pickle\"\n",
    "with open(savedPath, 'wb') as handle:\n",
    "    pickle.dump(modelMetricDic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Model metrics saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
